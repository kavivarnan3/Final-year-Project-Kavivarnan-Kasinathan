{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJhAxmnq1fAM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models, callbacks, utils\n",
        "from tensorflow.keras.applications import VGG16, MobileNetV2, ResNet50, DenseNet121\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "_YzIGYGp1g48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceDetectionSystem:\n",
        "    def __init__(self, base_path, img_size=(224, 224)):\n",
        "        self.base_path = base_path\n",
        "        self.img_size = img_size\n",
        "        self.categories = ['WithMask', 'WithoutMask']\n",
        "        self.models = {}\n",
        "        self.histories = {}\n",
        "        self.results = {}\n",
        "\n",
        "        # Initialize face detector for multi-face detection\n",
        "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    def load_and_preprocess_data(self):\n",
        "        \"\"\"Load and preprocess data with face detection\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "        data = []\n",
        "\n",
        "        for label, category in enumerate(self.categories):\n",
        "            cat_dir = os.path.join(self.base_path, category)\n",
        "            if not os.path.exists(cat_dir):\n",
        "                print(f\"Warning: Directory {cat_dir} does not exist\")\n",
        "                continue\n",
        "\n",
        "            for fname in os.listdir(cat_dir):\n",
        "                img_path = os.path.join(cat_dir, fname)\n",
        "                if os.path.isfile(img_path) and fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img = cv2.imread(img_path)\n",
        "                    if img is not None:\n",
        "                        # Detect faces in the image\n",
        "                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "                        if len(faces) > 0:\n",
        "                            # Process each detected face\n",
        "                            for (x, y, w, h) in faces:\n",
        "                                face_img = img[y:y+h, x:x+w]\n",
        "                                face_img = cv2.resize(face_img, self.img_size)\n",
        "                                data.append((face_img, label))\n",
        "                        else:\n",
        "                            # If no face detected, use whole image\n",
        "                            img = cv2.resize(img, self.img_size)\n",
        "                            data.append((img, label))\n",
        "\n",
        "        random.shuffle(data)\n",
        "        X = np.array([d[0] for d in data])\n",
        "        y = np.array([d[1] for d in data])\n",
        "\n",
        "        print(f\"Loaded {len(X)} images\")\n",
        "        print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def prepare_data(self, X, y):\n",
        "        \"\"\"Split and prepare data for training\"\"\"\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "            X, y, test_size=0.3, stratify=y, random_state=42\n",
        "        )\n",
        "        X_val, X_test, y_val, y_test = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        "        )\n",
        "\n",
        "        # Convert to categorical\n",
        "        y_train_cat = utils.to_categorical(y_train, num_classes=2)\n",
        "        y_val_cat = utils.to_categorical(y_val, num_classes=2)\n",
        "        y_test_cat = utils.to_categorical(y_test, num_classes=2)\n",
        "\n",
        "        return (X_train, X_val, X_test), (y_train_cat, y_val_cat, y_test_cat), (y_train, y_val, y_test)\n",
        "\n",
        "    def create_custom_model(self):\n",
        "        \"\"\"Create custom CNN model from scratch\"\"\"\n",
        "        model = models.Sequential([\n",
        "            layers.Input(shape=(224, 224, 3)),\n",
        "            layers.Rescaling(1.0 / 255),\n",
        "\n",
        "            # First Conv Block\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.25),\n",
        "\n",
        "            # Second Conv Block\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.25),\n",
        "\n",
        "            # Third Conv Block\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.25),\n",
        "\n",
        "            # Fourth Conv Block\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Dropout(0.25),\n",
        "\n",
        "            # Classification Head\n",
        "            layers.GlobalAveragePooling2D(),\n",
        "            layers.Dense(512, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(256, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(2, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_transfer_learning_model(self, base_model_name):\n",
        "        \"\"\"Create transfer learning model\"\"\"\n",
        "        if base_model_name == 'VGG16':\n",
        "            base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "        elif base_model_name == 'MobileNetV2':\n",
        "            base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "        elif base_model_name == 'ResNet50':\n",
        "            base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "        elif base_model_name == 'DenseNet121':\n",
        "            base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "        base_model.trainable = False\n",
        "\n",
        "        model = models.Sequential([\n",
        "            layers.Input(shape=(224, 224, 3)),\n",
        "            layers.Rescaling(1.0 / 255),\n",
        "            base_model,\n",
        "            layers.GlobalAveragePooling2D(),\n",
        "            layers.Dense(256, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(2, activation='softmax')\n",
        "        ])\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train_model(self, model, model_name, X_train, X_val, y_train, y_val):\n",
        "        \"\"\"Train a model with proper callbacks\"\"\"\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        # Data augmentation\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True,\n",
        "            fill_mode='nearest'\n",
        "        )\n",
        "        datagen.fit(X_train)\n",
        "\n",
        "        # Callbacks\n",
        "        early_stop = callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            verbose=1,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=0.0001,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        checkpoint = callbacks.ModelCheckpoint(\n",
        "            f'best_{model_name.lower()}_model.h5',\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Training\n",
        "        history = model.fit(\n",
        "            datagen.flow(X_train, y_train, batch_size=32),\n",
        "            steps_per_epoch=len(X_train) // 32,\n",
        "            epochs=25,\n",
        "            validation_data=(X_val, y_val),\n",
        "            callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return model, history\n",
        "\n",
        "    def evaluate_model(self, model, model_name, X_test, y_test, y_test_orig):\n",
        "        \"\"\"Evaluate model and return metrics\"\"\"\n",
        "        print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        # Metrics\n",
        "        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "        # Classification report\n",
        "        report = classification_report(\n",
        "            y_test_orig,\n",
        "            y_pred_classes,\n",
        "            target_names=self.categories,\n",
        "            output_dict=True\n",
        "        )\n",
        "\n",
        "        # Confusion matrix\n",
        "        cm = confusion_matrix(y_test_orig, y_pred_classes)\n",
        "\n",
        "        return {\n",
        "            'test_loss': test_loss,\n",
        "            'test_accuracy': test_accuracy,\n",
        "            'classification_report': report,\n",
        "            'confusion_matrix': cm,\n",
        "            'predictions': y_pred_classes,\n",
        "            'true_labels': y_test_orig\n",
        "        }\n",
        "\n",
        "    def plot_improved_confusion_matrix(self, cm, model_name):\n",
        "        \"\"\"Plot improved confusion matrix\"\"\"\n",
        "        plt.figure(figsize=(10, 8))\n",
        "\n",
        "        # Create annotation matrix\n",
        "        group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
        "        group_counts = [f\"{value:0.0f}\" for value in cm.flatten()]\n",
        "        group_percentages = [f\"{value:.1%}\" for value in cm.flatten()/np.sum(cm)]\n",
        "\n",
        "        labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
        "        labels = np.asarray(labels).reshape(2, 2)\n",
        "\n",
        "        # Create heatmap\n",
        "        sns.heatmap(\n",
        "            cm,\n",
        "            annot=labels,\n",
        "            fmt='',\n",
        "            cmap='Blues',\n",
        "            cbar_kws={'label': 'Count'},\n",
        "            xticklabels=self.categories,\n",
        "            yticklabels=self.categories,\n",
        "            linewidths=2,\n",
        "            linecolor='white'\n",
        "        )\n",
        "\n",
        "        plt.title(f'{model_name} - Confusion Matrix\\n', fontsize=16, fontweight='bold')\n",
        "        plt.xlabel('Predicted Label', fontsize=12)\n",
        "        plt.ylabel('True Label', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'confusion_matrix_{model_name.lower()}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_training_history(self, history, model_name):\n",
        "        \"\"\"Plot training history with val_accuracy vs val_loss\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "        # Accuracy plot\n",
        "        axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
        "        axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
        "        axes[0, 0].set_title(f'{model_name} - Model Accuracy')\n",
        "        axes[0, 0].set_xlabel('Epoch')\n",
        "        axes[0, 0].set_ylabel('Accuracy')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "        axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
        "        axes[0, 1].set_title(f'{model_name} - Model Loss')\n",
        "        axes[0, 1].set_xlabel('Epoch')\n",
        "        axes[0, 1].set_ylabel('Loss')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Val Accuracy vs Val Loss (Teacher's specific requirement)\n",
        "        axes[1, 0].plot(history.history['val_loss'], history.history['val_accuracy'],\n",
        "                       'bo-', linewidth=2, markersize=6)\n",
        "        axes[1, 0].set_title(f'{model_name} - Val Accuracy vs Val Loss')\n",
        "        axes[1, 0].set_xlabel('Validation Loss')\n",
        "        axes[1, 0].set_ylabel('Validation Accuracy')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Learning rate (if available)\n",
        "        if 'lr' in history.history:\n",
        "            axes[1, 1].plot(history.history['lr'], linewidth=2)\n",
        "            axes[1, 1].set_title(f'{model_name} - Learning Rate')\n",
        "            axes[1, 1].set_xlabel('Epoch')\n",
        "            axes[1, 1].set_ylabel('Learning Rate')\n",
        "            axes[1, 1].set_yscale('log')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "        else:\n",
        "            axes[1, 1].text(0.5, 0.5, 'Learning Rate\\nNot Recorded',\n",
        "                          ha='center', va='center', transform=axes[1, 1].transAxes)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'training_history_{model_name.lower()}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        # Explain why val_loss might increase\n",
        "        print(f\"\\n--- Analysis for {model_name} ---\")\n",
        "        print(\"Why validation loss might increase:\")\n",
        "        print(\"1. Overfitting: Model memorizes training data but fails on validation\")\n",
        "        print(\"2. Learning rate too high: Causes oscillations in loss\")\n",
        "        print(\"3. Insufficient regularization: Model complexity exceeds data complexity\")\n",
        "        print(\"4. Data imbalance: Model biased towards majority class\")\n",
        "        print(\"5. Batch size effects: Small batches can cause noisy gradients\")\n",
        "\n",
        "    def detect_multiple_faces(self, image_path, model):\n",
        "        \"\"\"Detect and classify multiple faces in an image\"\"\"\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            return None, None\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        results = []\n",
        "        img_with_boxes = img.copy()\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Extract face\n",
        "            face_img = img[y:y+h, x:x+w]\n",
        "            face_resized = cv2.resize(face_img, self.img_size)\n",
        "            face_normalized = face_resized.astype('float32') / 255.0\n",
        "            face_batch = np.expand_dims(face_normalized, axis=0)\n",
        "\n",
        "            # Predict\n",
        "            prediction = model.predict(face_batch, verbose=0)\n",
        "            class_idx = np.argmax(prediction)\n",
        "            confidence = np.max(prediction)\n",
        "            label = self.categories[class_idx]\n",
        "\n",
        "            results.append({\n",
        "                'bbox': (x, y, w, h),\n",
        "                'label': label,\n",
        "                'confidence': confidence\n",
        "            })\n",
        "\n",
        "            # Draw bounding box\n",
        "            color = (0, 255, 0) if label == 'with_mask' else (0, 0, 255)\n",
        "            cv2.rectangle(img_with_boxes, (x, y), (x+w, y+h), color, 2)\n",
        "            cv2.putText(img_with_boxes, f'{label}: {confidence:.2f}',\n",
        "                       (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        return results, img_with_boxes\n",
        "\n",
        "    def run_complete_pipeline(self):\n",
        "        \"\"\"Run the complete face detection pipeline\"\"\"\n",
        "        print(\"=== Face Detection System - Complete Pipeline ===\")\n",
        "\n",
        "        # Load data\n",
        "        X, y = self.load_and_preprocess_data()\n",
        "        (X_train, X_val, X_test), (y_train, y_val, y_test), (y_train_orig, y_val_orig, y_test_orig) = self.prepare_data(X, y)\n",
        "\n",
        "        # Model names to train\n",
        "        model_names = ['Custom_CNN', 'VGG16', 'MobileNetV2', 'ResNet50', 'DenseNet121']\n",
        "\n",
        "        # Train all models\n",
        "        for model_name in model_names:\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"Processing {model_name}\")\n",
        "            print(f\"{'='*50}\")\n",
        "\n",
        "            # Create model\n",
        "            if model_name == 'Custom_CNN':\n",
        "                model = self.create_custom_model()\n",
        "            else:\n",
        "                model = self.create_transfer_learning_model(model_name)\n",
        "\n",
        "            print(f\"{model_name} Model Summary:\")\n",
        "            model.summary()\n",
        "\n",
        "            # Train model\n",
        "            trained_model, history = self.train_model(\n",
        "                model, model_name, X_train, X_val, y_train, y_val\n",
        "            )\n",
        "\n",
        "            # Store results\n",
        "            self.models[model_name] = trained_model\n",
        "            self.histories[model_name] = history\n",
        "\n",
        "            # Evaluate model\n",
        "            results = self.evaluate_model(\n",
        "                trained_model, model_name, X_test, y_test, y_test_orig\n",
        "            )\n",
        "            self.results[model_name] = results\n",
        "\n",
        "            # Plot results\n",
        "            self.plot_training_history(history, model_name)\n",
        "            self.plot_improved_confusion_matrix(results['confusion_matrix'], model_name)\n",
        "\n",
        "            # Print results\n",
        "            print(f\"\\n{model_name} Results:\")\n",
        "            print(f\"Test Accuracy: {results['test_accuracy']:.4f}\")\n",
        "            print(f\"Test Loss: {results['test_loss']:.4f}\")\n",
        "            print(\"\\nClassification Report:\")\n",
        "            for class_name in self.categories:\n",
        "                metrics = results['classification_report'][class_name]\n",
        "                print(f\"{class_name}: Precision={metrics['precision']:.3f}, \"\n",
        "                      f\"Recall={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}\")\n",
        "\n",
        "        # Compare all models\n",
        "        self.compare_models()\n",
        "\n",
        "        return self.models, self.results\n",
        "\n",
        "    def compare_models(self):\n",
        "        \"\"\"Compare all models performance\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"MODEL COMPARISON SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        comparison_data = []\n",
        "        for model_name, results in self.results.items():\n",
        "            comparison_data.append({\n",
        "                'Model': model_name,\n",
        "                'Accuracy': results['test_accuracy'],\n",
        "                'Loss': results['test_loss'],\n",
        "                'With_Mask_F1': results['classification_report']['with_mask']['f1-score'],\n",
        "                'Without_Mask_F1': results['classification_report']['without_mask']['f1-score']\n",
        "            })\n",
        "\n",
        "        # Sort by accuracy\n",
        "        comparison_data.sort(key=lambda x: x['Accuracy'], reverse=True)\n",
        "\n",
        "        print(f\"{'Model':<15} {'Accuracy':<10} {'Loss':<10} {'With_Mask_F1':<12} {'Without_Mask_F1':<15}\")\n",
        "        print(\"-\" * 70)\n",
        "        for data in comparison_data:\n",
        "            print(f\"{data['Model']:<15} {data['Accuracy']:<10.4f} {data['Loss']:<10.4f} \"\n",
        "                  f\"{data['With_Mask_F1']:<12.4f} {data['Without_Mask_F1']:<15.4f}\")\n",
        "\n",
        "        # Plot comparison\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        models = [d['Model'] for d in comparison_data]\n",
        "        accuracies = [d['Accuracy'] for d in comparison_data]\n",
        "\n",
        "        bars = plt.bar(models, accuracies, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'])\n",
        "        plt.title('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
        "        plt.xlabel('Models')\n",
        "        plt.ylabel('Test Accuracy')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, acc in zip(bars, accuracies):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
        "                    f'{acc:.3f}', ha='center', va='bottom')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "LSxCRPVF12rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage and application\n",
        "def create_face_detection_app():\n",
        "    \"\"\"Create a simple face detection application\"\"\"\n",
        "    print(\"=== Face Detection Application ===\")\n",
        "\n",
        "    # Initialize the system\n",
        "    # Note: Update this path to your actual dataset path\n",
        "    #from google.colab import drive\n",
        "   # base_path = drive.mount('/content/drive')  # Update this path\n",
        "    base_path = \"/content/drive/MyDrive/Face Mask Dataset/Train\"\n",
        "    system = FaceDetectionSystem(base_path)\n",
        "\n",
        "    # Check if models exist, if not train them\n",
        "    if not os.path.exists('best_custom_cnn_model.h5'):\n",
        "        print(\"Training models...\")\n",
        "        models, results = system.run_complete_pipeline()\n",
        "\n",
        "        # Save comparison results\n",
        "        with open('model_comparison_results.json', 'w') as f:\n",
        "            json.dump({\n",
        "                name: {\n",
        "                    'accuracy': float(results['test_accuracy']),\n",
        "                    'loss': float(results['test_loss'])\n",
        "                } for name, results in results.items()\n",
        "            }, f, indent=2)\n",
        "    else:\n",
        "        print(\"Loading existing models...\")\n",
        "        # Load best model (you can modify this to load your preferred model)\n",
        "        system.models['Custom_CNN'] = models.load_model('best_custom_cnn_model.h5')\n",
        "\n",
        "    return system"
      ],
      "metadata": {
        "id": "4iwG07t12GDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Create the face detection system\n",
        "    system = create_face_detection_app()\n",
        "\n",
        "    # If you want to test on a specific image with multiple faces\n",
        "    # Uncomment and modify the path below:\n",
        "    \"\"\"\n",
        "    test_image_path = \"/content/drive/MyDrive/Face-Detection/train/0-with-mask_jpg.rf.2dd114e4f143ba8bf221a0377529b7a5.jpg\"\n",
        "    if os.path.exists(test_image_path):\n",
        "        results, img_with_boxes = system.detect_multiple_faces(\n",
        "            test_image_path,\n",
        "            system.models['Custom_CNN']\n",
        "        )\n",
        "\n",
        "        if results:\n",
        "            print(f\"Detected {len(results)} faces:\")\n",
        "            for i, result in enumerate(results):\n",
        "                print(f\"Face {i+1}: {result['label']} (confidence: {result['confidence']:.3f})\")\n",
        "\n",
        "            # Display result\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
        "            plt.title('Multi-Face Detection Results')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n=== Setup Complete ===\")\n",
        "    print(\"To use the system:\")\n",
        "    print(\"1. Update the base_path variable to point to your dataset\")\n",
        "    print(\"2. Ensure your dataset has 'with_mask' and 'without_mask' folders\")\n",
        "    print(\"3. Run the complete pipeline to train and compare all models\")\n",
        "    print(\"4. Use detect_multiple_faces() for testing on new images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KkA6Spn62JYb",
        "outputId": "2255d4f5-b576-41c4-e002-bcaa53322560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Face Detection Application ===\n",
            "Training models...\n",
            "=== Face Detection System - Complete Pipeline ===\n",
            "Loading and preprocessing data...\n",
            "Loaded 10148 images\n",
            "Class distribution: [5113 5035]\n",
            "\n",
            "==================================================\n",
            "Processing Custom_CNN\n",
            "==================================================\n",
            "Custom_CNN Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,435,682\u001b[0m (5.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,435,682</span> (5.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,435,682\u001b[0m (5.48 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,435,682</span> (5.48 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Custom_CNN...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iNE4_KAN4Jkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}